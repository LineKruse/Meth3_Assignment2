---
title: "Assignment 1 - Language Development in ASD - part 4"
author: "Riccardo Fusaroli"
date: "August 10, 2017"
output: html_document
---

```{r setup, include=FALSE}
setwd("~/Documents/Experimental Methods III/Assignment_1")
knitr::opts_chunk$set(echo = TRUE)
```

## Welcome to the fourth exciting part of the Language Development in ASD exercise

In this exercise we will assess how many participants we would need to adequately replicate our findings (ensuring our sample size is adequate, our alpha at 0.05 and our beta at 0.8).

### Exercise 1

How much power does your study have (if your model estimates are quite right)?
- [GitHub]Load your dataset, fit your favorite model, assess power for your main effects and interactions of interest.
- Report the power analysis and comment on what you can (or cannot) use its estimates for.
```{r setup, include=FALSE}
library(dplyr)
install.packages("simr")
library(simr)

data <- read.csv("~/Documents/Experimental Methods III/Assignment_1/Autism_data.csv")

data = dplyr::rename(data, ADOS = ADOS.y)
data = dplyr::rename(data, nonVerbalIQ = nonVerbalIQ.y)
data = dplyr::rename(data, VerbalIQ = VerbalIQ.y)

mainef_model = lmer(CHI_MLU~MOT_MLU+types_CHI+VerbalIQ+(1+VISIT|SUBJ), data, REML=F)
summary(mainef_model)

model = lmer(CHI_MLU~MOT_MLU*types_CHI+VerbalIQ+(1+VISIT|SUBJ), data, REML=F)
summary(model)

powerMain_MOTMLU = powerSim(mainef_model,fixed("MOT_MLU"),nsim=200)
powerMain_typesCHI = powerSim(mainef_model,fixed("types_CHI"),nsim=200)
powerMain_VerbalIQ = powerSim(mainef_model,fixed("VerbalIQ"),nsim=200)

powerMain_MOTMLU
#Power = 100% (98.17, 100)

powerMain_typesCHI
#Power = 100% (98.17, 100)

powerMain_VerbalIQ
#Power = 29.5 % (23.28, 36.34)

powerInt = powerSim(model,fixed("MOT_MLU:types_CHI"),nsim=200) 
powerInt
#Power = 100% (98.17, 100)

#Answer:
#Assuming that the effect size of parental MLU is 0.28 as estimated by the model, and the sample size is constant at 61 participants, the power of this main effect is 100% (98.17, 100)

#Assuming that the effect size of unique words the child uses is 0.008 as estimated by the model, and the sample size is constant at 61 participants, the power of this main effect is 100% (98.17, 100)

#Assuming that the effect size of the Verbal IQ of the child is 0.01 as estimated by the model, and the sample size is constant at 61 participants, the power of this main effect is 29.5% (23.28, 36.34)

#Assuming that the effect size of an interaction between parental MLU and unique words used by the child is 0.003 as estimated by the model, and the sample size is constant at 61 participants, the power of this interaction effect is 100% (98.17, 100)

#Comment: can we use this? WHat are the limitations of this?
```
### Exercise 2

How would you perform a more conservative power analysis?
- Identify and justify a minimum effect size for each of your relevant effects
- [GitHub] take the model from exercise 1 and replace the effects with the minimum effect size that you'd accept.
- [GitHub] assess the power curve by Child.ID, identifying an ideal number of participants to estimate each effect
- OPTIONAL if your power estimates do not reach an acceptable threshold simulate additional participants and repeat the previous analysis
- Report the power analysis and comment on what you can (or cannot) use its estimates for.

```{r}
#Choosing the minimal effect size we want to find - assessing how many participants is needed for each parameter to get this minimum effect 
#Looking at main effects
fixef(mainef_model)["MOT_MLU"] <- 0.2
fixef(mainef_model)["types_CHI"] <- 0.008
fixef(mainef_model)["VerbalIQ"] <- 0.01

powerCurve_MOTMLU = powerCurve(mainef_model, fixed("MOT_MLU"),along="SUBJ", nsim=200)
powerCurve_MOTMLU
plot(powerCurve_MOTMLU)
#To get an effect size of 0.2 with power>80%, we need approximately 20 participants 

powerCurve_typesCHI = powerCurve(mainef_model, fixed("types_CHI"),along="SUBJ", nsim=200)
powerCurve_typesCHI
plot(powerCurve_typesCHI)
#To get an effect size of 0.008, with power>80%, we need only 1 participant

powerCurve_VerbalIQ = powerCurve(mainef_model, fixed("VerbalIQ"),along="SUBJ", nsim=200)
powerCurve_VerbalIQ
plot(powerCurve_VerbalIQ)
#To get an effect size of 0.01, even with 61 participants, power is still only 41%. 
#ASK RICCARDO HOW TO CHANGE THE FUNCTION TO GENERATE NEW PARTICIPANTS - to discover the needed number of participants 

#Looking at interaction effects 
fixef(model)["MOT_MLU:types_CHI"] <- 0.002
fixef(model)["VerbalIQ"] <- 0.002

powerCurve_Int = powerCurve(model, fixed("MOT_MLU:types_CHI"),along="SUBJ", nsim=200)
powerCurve_Int
plot(powerCurve_Int)
#To obtain an effect size of 0.002, with power>80%, we need approximately 27 participants. 

powerCurve_Int_VerbalIQ = powerCurve(model, fixed("VerbalIQ"),along="SUBJ", nsim=200)
powerCurve_Int_VerbalIQ
plot(powerCurve_Int_VerbalIQ)
#With an effect size of 0.002, even with 61 participants we only have 5% power. #SIMULATE NEW PARTICIPANTS! 


###OPTIONAL
### Riccardo's clumsy function to simulate new participants
### TO DO points are only notes for myself, so not part of the assignment
# This function is made according to the model: 
# model = lmer(CHI_MLU~Visit*Diagnosis+(1+VISIT|SUBJ), data, REML=F)

createNewData <- function (participants,visits,model){
  # participants is the number of subjects
  # visits is the number of visits
  # TO DO: LOOP THROUGH ALL FE ROWS AND AUTOMATICALLY EXTRACT NAMES OF FIXED EFFECTS AND ESTIMATES
  fe <- fixef(model)
  Intercept <- fe[1] #intercept
  bVisit <- fe[2] #visit
  bDiagnosis <- fe[3] #diagnosis
  bVisitDiagnosis <- fe[4] #visit diagnosis interaction
  # TO DO: INTEGRATE STANDARD ERROR?
  
  # TO DO: LOOP THROUGH ALL VC COMPONENTS AND AUTOMATICALLY EXTRACT NAMES OF EFFECTS AND ESTIMATES
  vc<-VarCorr(model) # variance component
  sigmaSubject <- as.numeric(attr(vc[[1]],"stddev")[1]) # random intercept by subject
  sigmaVisit <- as.numeric(attr(vc[[1]],"stddev")[2]) # random slope of visit over subject
  sigmaResiduals <- as.numeric(attr(vc,"sc"))
  sigmaCorrelation <- as.numeric(attr(vc[[1]],"correlation")[2])
  
  # Create an empty dataframe
  d=expand.grid(Visit=1:visits,Child.ID=1:participants)
  # Randomly sample from a binomial (to generate the diagnosis)
  condition <- sample(rep(0:1, participants/2))
  d$Diagnosis<-condition[d$Child.ID]
  d$Diagnosis[is.na(d$Diagnosis)]<-1
  
  ## Define variance covariance matrices:
  Sigma.u<-matrix(c(sigmaSubject^2,
                    sigmaCorrelation*sigmaSubject*sigmaVisit,
                    sigmaCorrelation*sigmaSubject*sigmaVisit,
                    sigmaVisit^2),nrow=2)
  
  ## generate new fake participants (column1=RandomIntercept, column2=RandomSlope)
  u<-mvrnorm(n=participants,
             mu=c(0,0),Sigma=cov(ranef(model)$Child.ID))
  
  ## now generate fake data:
  ### the outcome is extracted from a gaussian with
  ### the solution to the model's equation as mean and
  ### the residual standard deviation as standard deviation 
  d$CHI_MLU <- rnorm(participants*visits,
                     (Intercept+u[,1]) +
                     (bVisit+u[,2])*d$Visit + 
                     bDiagnosis*d$Diagnosis ,sigmaResiduals)  
  
  return(d)
}
```


### Exercise 3

Assume you have only the resources to collect 30 kids (15 with ASD and 15 TDs). Identify the power for each relevant effect and discuss whether it's worth to run the study and why.

```{r}
#Running simulations with different effect sizes, until the power is above 80% for 30 participants - that's the effect of each parameter we can get with 30 participants

#Looking at main effects
fixef(mainef_model)["MOT_MLU"] <- 0.17
fixef(mainef_model)["types_CHI"] <- 0.002
fixef(mainef_model)["VerbalIQ"] <- 0.026

powerCurve_MOTMLU = powerCurve(mainef_model, fixed("MOT_MLU"),along="SUBJ", nsim=20)
powerCurve_MOTMLU
plot(powerCurve_MOTMLU)
#With 30 participants, and power>80%, we can obtain an effect size of 0.17 (estimate) for parental MLU 

powerCurve_typesCHI = powerCurve(mainef_model, fixed("types_CHI"),along="SUBJ", nsim=20)
powerCurve_typesCHI
plot(powerCurve_typesCHI)
#With 30 participants, and power>80%, we can obtain an effect size of 0.002 (estimate) for amount of unique words produced by the child

powerCurve_VerbalIQ = powerCurve(mainef_model, fixed("VerbalIQ"),along="SUBJ", nsim=20)
powerCurve_VerbalIQ
plot(powerCurve_VerbalIQ)
#With 30 participants, and power>80%, we can obtain an effect size of 0.026 for the Verbal IQ of the child 

#Looking at interaction effects 
fixef(model)["MOT_MLU:types_CHI"] <- 0.0018
fixef(model)["VerbalIQ"] <- 0.022

powerCurve_Int = powerCurve(model, fixed("MOT_MLU:types_CHI"),along="SUBJ", nsim=200)
powerCurve_Int
plot(powerCurve_Int)
#With 30 participants, and power>80%, we can obtain an effect size of 0.0018 for the interaction between parental MLU and unique words produced by the child

powerCurve_Int_VerbalIQ = powerCurve(model, fixed("VerbalIQ"),along="SUBJ", nsim=200)
powerCurve_Int_VerbalIQ
plot(powerCurve_Int_VerbalIQ)
#With 30 participants, and power>80%, we can obtain an effect size of 0.022, for the verbal IQ of the child

```

